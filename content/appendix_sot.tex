\begin{appendices}

\chapter{Local Constraints}
\label{app:local-constr}

Let consider two tasks with jacobians $\mathbf{J}_1$ and $\mathbf{J}_2$, with the first one at highest priority. Let consider also a constraint on the first task of the type:
\begin{equation}
\mathbf{A}\mathbf{\dot{q}} \leq \mathbf{b}
\end{equation}
with:
\begin{equation}
rank\left ( \begin{bmatrix}
\mathbf{J}_1\\ 
\mathbf{A}
\end{bmatrix} \right ) = rank \left( \mathbf{J}_1 \right)
\end{equation}
This means that $\mathbf{A}$ can be written as a linear combination of rows of $\mathbf{J}_1$:
\begin{equation}
\label{app:linear-comb}
\mathbf{A} = \mathbf{BJ}_1
\end{equation}
The first qp that is solved is:
\begin{equation} 
\label{app:qp1}
\begin{array}{c}
\mathbf{\dot{q}}* = \underset{\mathbf{\dot{q}}}{\operatorname{argmin}} \ \Arrowvert \mathbf{J}_1 \mathbf{\dot{q}}-\mathbf{v}_{d,1} \Arrowvert\\
s.t. \ \mathbf{A}\mathbf{\dot{q}} \leq \mathbf{b}
\end{array}
\end{equation}

where $\mathbf{\dot{q}}*$ satisfy the constraint and minimize the cost function. 
The second qp that is solved is:
\begin{equation} 
\label{app:qp2}
\begin{array}{c}
\underset{\mathbf{\dot{q}}}{\operatorname{min}} \ \Arrowvert \mathbf{J}_2 \mathbf{\dot{q}}-\mathbf{v}_{d,2} \Arrowvert\\
s.t. \ \mathbf{J}_1\mathbf{\dot{q}} = \mathbf{J}_1\mathbf{\dot{q}}*
\end{array}
\end{equation}
where the equality constraint guarantee the optimality of the previous solution. If we multiply the constraint for the $\mathbf{B}$ matrix considering (\ref{app:linear-comb}) and the constraint satisfied in (\ref{app:qp1}):
\begin{equation}
\mathbf{B}\mathbf{J}_1\mathbf{\dot{q}} = \mathbf{B}\mathbf{J}_1\mathbf{\dot{q}}* \leq \mathbf{b}
\end{equation}
therefore:
\begin{equation}
\mathbf{B}\mathbf{J}_1\mathbf{\dot{q}} = \mathbf{A}\mathbf{\dot{q}}\leq \mathbf{b}
\end{equation}
so the constraint remains satisfied also in the second qp \emph{qed}.

\chapter{Singularity Robustness}
\label{app:singularity-robustness}

Let consider the following minimization problem:
\begin{equation} 
\label{SRI_problem}
\begin{array}{c}
\underset{\mathbf{\dot{q}}}{\operatorname{argmin}} \ \Arrowvert \mathbf{J}_i \mathbf{\dot{q}}_i-\mathbf{v}_{d,i} \Arrowvert + \lambda \Arrowvert \mathbf{\dot{q}}_i \Arrowvert
\end{array}
\end{equation}
the Lagrangian is computed:
\begin{equation}
\label{SRI_Lagrangian}
l(\mathbf{\dot{q}}) = \mathbf{\dot{q}}'\mathbf{J}'\mathbf{J}\mathbf{\dot{q}}-2(\mathbf{J}\mathbf{\dot{q}})'\mathbf{v}-\mathbf{v}'\mathbf{v}+\lambda\mathbf{\dot{q}}'\mathbf{\dot{q}}
\end{equation}
and its derivative:
\begin{equation}
\label{derive_SRI_Lagrangian}
\frac{\partial l(\mathbf{\dot{q}})}{\partial\mathbf{\dot{q}}}=\mathbf{J}'\mathbf{J}\mathbf{\dot{q}}-\mathbf{J}'\mathbf{v}+\lambda\mathbf{\dot{q}}=0
\end{equation}
solving for $\dot{\mathbf{q}}$ leads to:
\begin{equation}
\label{SRI}
\mathbf{\dot{q}}=(\mathbf{J}'\mathbf{J}+\lambda\mathbf{I})^{-1}\mathbf{J}'\mathbf{v}
\end{equation}
notice that $(\mathbf{J}'\mathbf{J}+\lambda\mathbf{I})^{-1}\mathbf{J}' = \mathbf{J}'(\mathbf{J}\mathbf{J}'+\lambda\mathbf{I})^{-1}$ and it is called \emph{Singularity Robust Inverse} (SRI) of matrix $\mathbf{J}$ \cite{Nakamura:90}.
It is worth to notice that applying the SRI to the Singular Value Decomposition of a matrix leads to the Damped Singular Value Decomposition of that matrix, in fact, given a matrix $\mathbf{A}$ its SVD is:
\begin{equation}
\mathbf{A} = U\Sigma V'
\end{equation}
where $U$ is a unitary matrix, $\Sigma$ is the matrix of the ordered singular values $\sigma_1 \geq \sigma_2 \geq ... \geq 0$ and $V$ is a unitary matrix. The pseudo inverse of $\mathbf{A}$ can be written as:
\begin{equation}
\mathbf{A}^{\dagger} = V\Sigma^{\dagger}U'
\end{equation}
where the general non-zero element of $\Sigma^{\dagger}$ is $1/\sigma_i$ that became unstable when $\sigma_i$ goes to 0. Applying the SRI to $\Sigma$ leads to:
\begin{equation}
\Sigma^{\dagger} = (\Sigma'\Sigma+\lambda\mathbf{I})^{-1}\Sigma'
\end{equation}
where in this case the non-zero elements have the form $\frac{\sigma_i}{\sigma_i^2+\lambda}$ that is well known \cite{Maciejewski:89} SR form for the pseudo inverse.

\chapter{Weighted Pseudo-Inverse}
\label{app:weighted-pseudo-inverse}

When the last task in the stack is the minimization of the joint velocity, considering the optimality conditions from the previous tasks, the resulting problem is equivalent to the solution given by a weighted pseudo inverse. 
The following optimization problem is considered:
\begin{equation} 
\label{weighted_pseudoinverse}
\begin{array}{c}
\underset{\dot{\mathbf{q}}}{\operatorname{argmin}} \ \Arrowvert \dot{\mathbf{q}_l} \Arrowvert_W \\
s.t. \ \mathbf{v}^* = \mathbf{J}_{l-1}\dot{\mathbf{q}}_l\\
\end{array}
\end{equation}
where $l$ is for \emph{last} and $\mathbf{v}^*$ is the result of the previous optimizations (the computed Cartesian velocities are \emph{filtered} at the last stack). The Lagrangian is:
\begin{equation}
l(\dot{\mathbf{q}}, \mu) = \dot{\mathbf{q}}_l^TW\dot{\mathbf{q}}_l + \mu^T(\mathbf{J}_{l-1}\dot{\mathbf{q}}_l - \mathbf{v}^*)
\end{equation}
where $\mu$ is a vector of \emph{Lagrange Multipliers}. The solution is found as:
\begin{equation}
\label{derivative_lagrangian}
\frac{\partial l(\dot{\mathbf{q}}, \mu)}{\partial\dot{\mathbf{q}}} = 2W\dot{\mathbf{q}}_l+\mathbf{J}_{l-1}^T\mu = 0
\end{equation}
together with:
\begin{equation}
\label{constraint}
\mathbf{J}_{l-1}\dot{\mathbf{q}}_l-\mathbf{v}^* = 0
\end{equation}
From (\ref{derivative_lagrangian}) we get:
\begin{equation}
\label{step1}
\dot{\mathbf{q}}_l = -\frac{1}{2}W^{-1}\mathbf{J}_{l-1}^T\mu 
\end{equation}
where $W$ is always invertible since it is diagonal and positive definite. Substituting (\ref{step1}) in (\ref{constraint}) is possible to compute $\mu$:
\begin{equation}
\label{lambda_step1}
\frac{1}{2}\mathbf{J}_{l-1}W^{-1}\mathbf{J}_{l-1}^T\mu + \mathbf{v}^* = 0
\end{equation}
therefore:
\begin{equation}
\label{lambda_step2}
\mu = -2(\mathbf{J}_{l-1}W^{-1}\mathbf{J}_{l-1}^T)^{-1}\mathbf{v}^*
\end{equation}
that substituted in (\ref{step1}) gives the solution:
\begin{equation}
\label{solution}
\dot{\mathbf{q}}_l = W^{-1}\mathbf{J}_{l-1}^T(\mathbf{J}_{l-1}W^{-1}\mathbf{J}_{l-1}^T)^{-1}\mathbf{v}^*
\end{equation}
that corresponds to the weighted pseudo inverse solution.
\end{appendices}